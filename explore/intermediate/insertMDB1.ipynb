{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = \"../result/inserted/2/quora/\"\n",
    "\n",
    "data_name = \"quora_last/k4/results quorak4 100 75 lrrs.json\"\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['thesis']\n",
    "result = db.quorak4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storing in mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_name, 'r') as result_file:\n",
    "    result_json = json.load(result_file)\n",
    "    for document in result_json[\"results\"]:\n",
    "        #remove predict and true value beacuase it creates DocumentTooLarge Error since one document is above 16MB\n",
    "#         del document[\"train_true_predict\"]\n",
    "#         del document[\"test_true_predict\"]\n",
    "        result.insert_one(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading json for validation and checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(data_loc+data_name+\".json\") as json_file: \n",
    "    data = json.load(json_file)\n",
    "    \n",
    "type(data[\"results\"])\n",
    "len(data[\"results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quora lr_mvdt 3 25 5 100 2\n",
      "quora lr_mvdt 3 25 5 100 5\n",
      "quora lr_mvdt 3 25 5 100 10\n"
     ]
    }
   ],
   "source": [
    "for i in data[\"results\"]:\n",
    "    print(i[\"dataset\"],i[\"algorithm\"], i[\"k_fold\"],i[\"d2v_vec_size\"], i[\"min_leaf_point\"],i[\"epochs\"], i[\"feature_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '20ng_CG_RM'\n",
    "vector_sizes_list = [10, 25, 50, 75, 100]\n",
    "algorithms_list = ['lr_mvdt', 'rs_mvdt']\n",
    "k = 5\n",
    "epochs_list = [100, 300, 500, 800, 1000]\n",
    "n_features_list = [2, 5, 10, 20, all]\n",
    "min_leaf_point_list = [5, 10, 15, 20, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_list = [['by_n_features', '$feature_size'],\n",
    "           ['by_min_leaf_points', '$min_leaf_point'],\n",
    "           ['by_epochs', '$epochs'],\n",
    "           ['by_vectors', '$d2v_vec_size'],\n",
    "           ['by_k_folds', '$k_fold'],\n",
    "           ['by_datasets', '$algorithm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 lr_mvdt\n",
      "10 rs_mvdt\n",
      "25 lr_mvdt\n",
      "25 rs_mvdt\n",
      "50 lr_mvdt\n",
      "50 rs_mvdt\n",
      "75 lr_mvdt\n",
      "75 rs_mvdt\n",
      "100 lr_mvdt\n",
      "100 rs_mvdt\n"
     ]
    }
   ],
   "source": [
    "for vector_size in vector_sizes_list:\n",
    "    for algorithm in algorithms_list:    \n",
    "        calculate(vector_size, algorithm)\n",
    "        print(vector_size, algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(vector_size, algorithm):    \n",
    "    query = [{'$match': {'dataset': dataset, 'd2v_vec_size': vector_size, 'algorithm': algorithm}},\n",
    "         {'$project':{'intermediate_result': 1}},        \n",
    "         ]\n",
    "    results = db['20ng_CG_RM'].aggregate(query)\n",
    "\n",
    "    for result in results:        \n",
    "        for i in result['intermediate_result']:\n",
    "            if i is not None:\n",
    "                new_result = {'dataset': dataset,\n",
    "                              'd2v_vec_size': vector_size,\n",
    "                              'algorithm': algorithm,                          \n",
    "                              'on_depth': i['on_depth'],\n",
    "                              'train_acc': i['accuracy'][0],\n",
    "                              'test_acc': i['accuracy'][1]\n",
    "                             }\n",
    "                \n",
    "                db.acc_vs_depth_ng.insert_one(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
