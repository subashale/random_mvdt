{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = \"../result/\"\n",
    "# previously inserted \n",
    "# \"results_cartimdbng20\"#\"results_server_imdbk3mid\"\n",
    "\n",
    "# second\n",
    "# \"resultsquora\", \n",
    "data_name = \"results quorak1 75v min 5 epochs100\"\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['thesis']\n",
    "result = db.imdb # imdb\n",
    "\n",
    "# if large database then improt via \n",
    "# mongoimport --db dbName --collection collectionName <fileName.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storing in mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"imdb.json\", 'r') as result_file:\n",
    "    result_json = json.load(result_file)\n",
    "    for document in result_json[\"results\"]:\n",
    "#         Insert by remove other attribute except branchsize and algorithm and dataset\n",
    "        #remove predict and true value beacuase it creates DocumentTooLarge Error since one document is above 16MB\n",
    "        del document[\"train_true_predict\"]\n",
    "        del document[\"test_true_predict\"]\n",
    "        del document[\"filename\"]\n",
    "        del document[\"k_fold\"]\n",
    "        del document[\"d2v_vec_size\"]\n",
    "        del document[\"epochs\"]\n",
    "        del document[\"min_leaf_point\"]\n",
    "        del document[\"feature_size\"]\n",
    "        del document[\"d2v_shape\"]\n",
    "        del document[\"run\"]\n",
    "        del document[\"accuracy\"]\n",
    "        del document[\"precision\"]\n",
    "        del document[\"accuracy\"]\n",
    "        del document[\"precision\"]\n",
    "        del document[\"recall\"]\n",
    "        del document[\"f1\"]\n",
    "        del document[\"confusion_matrix\"]\n",
    "        del document[\"inner_node\"]\n",
    "        del document[\"leaf_node\"]\n",
    "        del document[\"all_node\"]\n",
    "        del document[\"training_time\"]\n",
    "        del document[\"tree_location\"]\n",
    "        del document[\"intermediate_result\"]\n",
    "        result.insert_one(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading json for validation and checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(data_loc+data_name+\".json\") as json_file: \n",
    "    data = json.load(json_file)\n",
    "    \n",
    "type(data[\"results\"])\n",
    "len(data[\"results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quora lr_mvdt 3 25 5 100 2\n",
      "quora lr_mvdt 3 25 5 100 5\n",
      "quora lr_mvdt 3 25 5 100 10\n"
     ]
    }
   ],
   "source": [
    "for i in data[\"results\"]:\n",
    "    print(i[\"dataset\"],i[\"algorithm\"], i[\"k_fold\"],i[\"d2v_vec_size\"], i[\"min_leaf_point\"],i[\"epochs\"], i[\"feature_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'quora'\n",
    "vector_sizes_list = [10, 25, 50, 75, 100]\n",
    "algorithms_list = ['lr_mvdt', 'rs_mvdt']\n",
    "k = 5\n",
    "epochs_list = [100, 300, 500, 800, 1000]\n",
    "n_features_list = [2, 5, 10, 20, all]\n",
    "min_leaf_point_list = [5, 10, 15, 20, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_list = [['by_n_features', '$feature_size'],\n",
    "           ['by_min_leaf_points', '$min_leaf_point'],\n",
    "           ['by_epochs', '$epochs'],\n",
    "           ['by_vectors', '$d2v_vec_size'],\n",
    "           ['by_k_folds', '$k_fold'],\n",
    "           ['by_datasets', '$algorithm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 lr_mvdt\n",
      "10 rs_mvdt\n",
      "25 lr_mvdt\n",
      "25 rs_mvdt\n",
      "50 lr_mvdt\n",
      "50 rs_mvdt\n",
      "75 lr_mvdt\n",
      "75 rs_mvdt\n",
      "100 lr_mvdt\n",
      "100 rs_mvdt\n"
     ]
    }
   ],
   "source": [
    "for vector_size in vector_sizes_list:\n",
    "    for algorithm in algorithms_list:    \n",
    "        calculate(vector_size, algorithm)\n",
    "        print(vector_size, algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(vector_size, algorithm):    \n",
    "    query = [{'$match': {'dataset': dataset, 'd2v_vec_size': vector_size, 'algorithm': algorithm}},\n",
    "         {'$project':{'intermediate_result': 1}},        \n",
    "         ]\n",
    "    results = db['quora'].aggregate(query)\n",
    "\n",
    "    for result in results:        \n",
    "        for i in result['intermediate_result']:\n",
    "            if i is not None:\n",
    "                new_result = {'dataset': dataset,\n",
    "                              'd2v_vec_size': vector_size,\n",
    "                              'algorithm': algorithm,                          \n",
    "                              'on_depth': i['on_depth'],\n",
    "                              'train_acc': i['accuracy'][0],\n",
    "                              'test_acc': i['accuracy'][1]\n",
    "                             }\n",
    "                \n",
    "                db.acc_vs_depth_quora.insert_one(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###temp insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [{'$match': {'k_fold':3}}]\n",
    "results = db['temp_imdb'].aggregate(query)\n",
    "\n",
    "for result in results:\n",
    "    db.imdb.insert_one(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
