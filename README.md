# random_mvdt
A univariate decision tree is good it self but when data can be separate linearly its better to use multivariate concept. In multivariate we take combination of features to make decision boundary until all or some criteria meets. 

In this project we try two different way of achieving linear separation on normal decision tree, we will be using entropy and gini impurity to measure purity. 

1. First we use normal deterministic way of to find slope and intercept 
2. Then we utilized logistic regression algorithm just to find coefficient and use that to make tree

# Requirement
This project can be run as script and jupyter notebook
1. Numpy
2. Pandas
3. Scikit-learn
4. Matplotlib
